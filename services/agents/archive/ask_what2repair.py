import speech_recognition as sr
from langchain.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# ğŸ§ Initialize recognizer
recognizer = sr.Recognizer()

# ğŸ¤ Listen to user's voice input
with sr.Microphone() as source:
    print("ğŸ”Š Please ask your elevator repair question...")
    recognizer.adjust_for_ambient_noise(source, duration=0.5)
    audio = recognizer.listen(source)

    try:
        query = recognizer.recognize_google(audio)
        print(f"ğŸ—£ï¸ You asked: {query}")
    except sr.UnknownValueError:
        print("âŒ Could not understand the audio.")
        exit()
    except sr.RequestError as e:
        print(f"âŒ Error with speech recognition service: {e}")
        exit()

# ğŸ¤– Load embedding model using GPU
embeddings = HuggingFaceEmbeddings(
    model_name='sentence-transformers/all-MiniLM-L6-v2',
    model_kwargs={"device": "cuda"}
)

# ğŸ“š Load vectorstore (your pre-embedded PDF)
vectorstore = FAISS.load_local(
    "mx20_index", 
    embeddings, 
    allow_dangerous_deserialization=True
)

# ğŸ” Perform semantic search
results = vectorstore.similarity_search(query, k=2)

# ğŸ“„ Show results
print("\nğŸ”§ Matching sections from the elevator manual:")
for i, res in enumerate(results, 1):
    print(f"\n--- Match {i} ---\n{res.page_content.strip()}")
